## Let's talk - ASL (American Sign Language) recognition
### This project was done by:
- https://github.com/plazinho
- https://github.com/IlyaGaluzinskiy
- https://github.com/aabdysheva

### Let's talk was build in order to recognize and translate ASL gestures in real-time using computer vision (Project was build in two weeks)
- Let's talk currently able to recognize 39 gestures (26 letters, 10 words, 3 special signs)
- Let's talk was build using MediaPipe, OpenCV, Keras, Qt
- LSTM model for sign recognition was build using Keras and trained on dataset, that was collected during development (currently includes more than 5000 samples)
- user guide and list of available signs are located in the UI
- required libraries can be installed using requirements.txt file

Folder "for_model_training" includes scripts, that will allow you to create your own dataset.
